### 결정 트리
- **분류와 회귀에 모두 사용**.
- 노드 기반의 데이터 분할 방식으로, 특정 특성의 기준값을 중심으로 데이터를 분할.
#### 주요 파라미터
- `max_depth`: 트리의 최대 깊이.
- `min_samples_split`: 분할을 위한 최소 샘플 수.
- `max_features`: 분할에 사용할 최대 특성 수.
#### 모델 평가
- 훈련 데이터에 과적합되기 쉬움.
- 제한된 깊이(`max_depth`) 설정 시 일반화 성능 개선 가능.
#### 특성 중요도
- 트리 모델은 각 특성의 중요도를 계산해 제공.
- 값이 높을수록 해당 특성이 분할에 많이 사용됨.

### 랜덤 포레스트
- 여러 결정 트리의 앙상블.
- 각 트리는 무작위 샘플과 무작위 특성을 사용해 학습.
#### 주요 특징
- 과적합 방지.
- 특성 중요도 제공.
#### 주요 파라미터
- `n_estimators`: 생성할 트리의 수.
- `max_features`: 각 트리에서 사용할 특성 수.
- `max_depth`: 트리의 최대 깊이.
#### 모델 평가
- 테스트 세트 정확도가 높음
- 과적합 방지와 높은 예측 정확도를 제공.

### 그래디언트 부스팅
- 약한 학습기의 앙상블.
- 이전 모델의 오류를 보완하는 방식으로 학습.
#### 주요 특징
- 순차적 학습 방식.
- 학습률(`learning_rate`)과 트리의 최대 깊이(`max_depth`) 설정으로 과적합 제어.
#### 주요 파라미터
- `n_estimators`: 생성할 트리의 수.
- `learning_rate`: 학습 속도.
- `max_depth`: 각 트리의 최대 깊이.
#### 모델 평가:
- 적은 메모리 사용량.
- 높은 정확도.
- 과적합 가능성 있음.

### 신경망
- 다층 퍼셉트론(MLP)을 기반으로 한 지도 학습 모델.
#### 주요 특징
- 비선형 데이터 학습 가능.
- 은닉층(`hidden_layer_sizes`)과 활성화 함수(`activation`)를 조정하여 복잡도 제어.
#### 주요 파라미터
- `hidden_layer_sizes`: 은닉층의 유닛 수.
- `activation`: 활성화 함수(`relu`, `tanh`, 등).
- `max_iter`: 최대 반복 횟수.
- `alpha`: 규제 강도.
#### 데이터 스케일링
- 신경망 모델은 입력 데이터의 스케일에 민감.
- 평균 0, 표준 편차 1로 정규화 필요.
#### 모델 평가
- 충분한 반복과 적절한 규제로 높은 정확도 가능.
- 과적합 방지를 위해 규제 및 데이터 전처리 필요.